{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69396440",
   "metadata": {},
   "source": [
    "# Model Used for Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fd4ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7a39b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1(circle) avg bases @0.50: 0.5227\n",
      "Fold 2 F1(circle) avg bases @0.50: 0.6337\n",
      "Fold 3 F1(circle) avg bases @0.50: 0.7129\n",
      "Fold 4 F1(circle) avg bases @0.50: 0.6214\n",
      "Fold 5 F1(circle) avg bases @0.50: 0.5435\n",
      "\n",
      "Calibrated stacking OOF best F1(circle): 0.6647\n",
      "Best threshold: 0.6549999999999999\n",
      "\n",
      "Test prediction distribution: {np.int64(0): np.int64(707), np.int64(1): np.int64(85)}\n",
      "Saved Submission_STACKING_CALIBRATED.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load data\n",
    "# =========================\n",
    "train = pd.read_csv(\"dataset-train-vf.csv\")\n",
    "test  = pd.read_csv(\"dataset-test-vf.csv\")\n",
    "\n",
    "X_full = train.drop(columns=[\"ID\", \"y\"]).copy()\n",
    "y_full = train[\"y\"].astype(str).copy()\n",
    "\n",
    "test_ids = test[\"ID\"].copy()\n",
    "X_test = test.drop(columns=[\"ID\"]).copy()\n",
    "\n",
    "cat_cols = [\"f11\"]\n",
    "num_cols = [c for c in X_full.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Helper to get P(circle) even after calibration\n",
    "def p_circle_from_estimator(est, X):\n",
    "    proba = est.predict_proba(X)\n",
    "    classes = est.classes_\n",
    "    idx = list(classes).index(\"circle\")\n",
    "    return proba[:, idx]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# Define base learners\n",
    "# =========================\n",
    "# MLP pipeline (already probabilistic)\n",
    "mlp_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", MLPClassifier(\n",
    "        hidden_layer_sizes=(50,),\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=700,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# RF and ET as pipelines, then calibrated on each fold\n",
    "rf_pipe_raw = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=700,\n",
    "        max_depth=None,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "et_pipe_raw = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", ExtraTreesClassifier(\n",
    "        n_estimators=900,\n",
    "        max_depth=None,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# OOF meta features: [MLP, CalRF, CalET]\n",
    "# =========================\n",
    "X_meta_oof = np.zeros((len(X_full), 3), dtype=float)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_full, y_full), start=1):\n",
    "    X_tr, X_va = X_full.iloc[tr_idx], X_full.iloc[va_idx]\n",
    "    y_tr, y_va = y_full.iloc[tr_idx], y_full.iloc[va_idx]\n",
    "\n",
    "    # Fit MLP\n",
    "    mlp_pipe.fit(X_tr, y_tr)\n",
    "    p_mlp = mlp_pipe.predict_proba(X_va)[:, list(mlp_pipe.named_steps[\"model\"].classes_).index(\"circle\")]\n",
    "\n",
    "    # Fit and calibrate RF (sigmoid)\n",
    "    rf_cal = CalibratedClassifierCV(rf_pipe_raw, method=\"sigmoid\", cv=3)\n",
    "    rf_cal.fit(X_tr, y_tr)\n",
    "    p_rf = p_circle_from_estimator(rf_cal, X_va)\n",
    "\n",
    "    # Fit and calibrate ET (sigmoid)\n",
    "    et_cal = CalibratedClassifierCV(et_pipe_raw, method=\"sigmoid\", cv=3)\n",
    "    et_cal.fit(X_tr, y_tr)\n",
    "    p_et = p_circle_from_estimator(et_cal, X_va)\n",
    "\n",
    "    X_meta_oof[va_idx, 0] = p_mlp\n",
    "    X_meta_oof[va_idx, 1] = p_rf\n",
    "    X_meta_oof[va_idx, 2] = p_et\n",
    "\n",
    "    p_avg = X_meta_oof[va_idx].mean(axis=1)\n",
    "    pred_avg = np.where(p_avg >= 0.5, \"circle\", \"square\")\n",
    "    print(f\"Fold {fold} F1(circle) avg bases @0.50:\", round(f1_score(y_va, pred_avg, pos_label=\"circle\"), 4))\n",
    "\n",
    "# =========================\n",
    "# Meta model + threshold tuning on OOF\n",
    "# =========================\n",
    "meta = LogisticRegression(max_iter=3000, class_weight=\"balanced\", random_state=42)\n",
    "meta.fit(X_meta_oof, y_full)\n",
    "\n",
    "p_meta_oof = meta.predict_proba(X_meta_oof)[:, list(meta.classes_).index(\"circle\")]\n",
    "\n",
    "thresholds = np.linspace(0.05, 0.95, 181)\n",
    "best_t, best_f1 = None, -1.0\n",
    "for t in thresholds:\n",
    "    pred = np.where(p_meta_oof >= t, \"circle\", \"square\")\n",
    "    f1 = f1_score(y_full, pred, pos_label=\"circle\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = float(f1), float(t)\n",
    "\n",
    "print(\"\\nCalibrated stacking OOF best F1(circle):\", round(best_f1, 4))\n",
    "print(\"Best threshold:\", best_t)\n",
    "\n",
    "# =========================\n",
    "# Fit on ALL data and predict test\n",
    "# =========================\n",
    "mlp_pipe.fit(X_full, y_full)\n",
    "\n",
    "rf_cal_full = CalibratedClassifierCV(rf_pipe_raw, method=\"sigmoid\", cv=3)\n",
    "rf_cal_full.fit(X_full, y_full)\n",
    "\n",
    "et_cal_full = CalibratedClassifierCV(et_pipe_raw, method=\"sigmoid\", cv=3)\n",
    "et_cal_full.fit(X_full, y_full)\n",
    "\n",
    "p_mlp_test = mlp_pipe.predict_proba(X_test)[:, list(mlp_pipe.named_steps[\"model\"].classes_).index(\"circle\")]\n",
    "p_rf_test  = p_circle_from_estimator(rf_cal_full, X_test)\n",
    "p_et_test  = p_circle_from_estimator(et_cal_full, X_test)\n",
    "\n",
    "X_meta_test = np.column_stack([p_mlp_test, p_rf_test, p_et_test])\n",
    "p_meta_test = meta.predict_proba(X_meta_test)[:, list(meta.classes_).index(\"circle\")]\n",
    "\n",
    "y_test_label = np.where(p_meta_test >= best_t, \"circle\", \"square\")\n",
    "y_test_bin = np.where(y_test_label == \"circle\", 1, 0)\n",
    "\n",
    "unique, counts = np.unique(y_test_bin, return_counts=True)\n",
    "print(\"\\nTest prediction distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "submission = pd.DataFrame({\"ID\": test_ids, \"y\": y_test_bin})\n",
    "submission.to_csv(\"Submission_STACKING_CALIBRATED.csv\", index=False)\n",
    "print(\"Saved Submission_STACKING_CALIBRATED.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
